---
title       : Data Science Capstone
subtitle    : Final Project - Natural Language Processing
author      : Bernard NK
job         : August 20, 2015
framework   : io2012        # {io2012, html5slides, shower, dzslides, ...}
highlighter : highlight.js  # {highlight.js, prettify, highlight}
hitheme     : tomorrow      # 
widgets     : [mathjax]            # {mathjax, quiz, bootstrap}
mode        : selfcontained # {standalone, draft}
knit        : slidify::knit2slides
---

## Description of the prediction algorithm

The project is done in association with SwiftKey, a company developing a smart prediction technology for easier mobile typing. To predict the next word, this R algorithm was implemented:  
  
1) Get a corpus and identify appropriate tokens such as words, punctuation, and numbers.  

2) Build a model with the corpus to understand the distribution and relationship between the words, tokens, and phrases in the text.  

3) The prediction algorithm is based on a predictor variable that is the n-gram frequency, to determine the next word that a user is most likely to type.  

4) Match a n-gram character string with the appropriate n+1 gram entry in the n-gram frequency Table. Tri-grams were found to be more reliable predictor variables.  

5) If there is a match, propose a high frequency word to the user.  

--- .class #id 

## Description of the Shiny application

How to use the predictive application:  
  
1. Click on this link: https://bernardnk.shinyapps.io/FinalProject  
2. Input on the left: Enter a phrase in the edit box and click "Predict!".  
3. Output on the right: Observe the predicted next word, expected to follow the phrase you entered.  
4. "NA": If the next word cannot be predicted, then "NA" will be displayed in the output.  

--- .class #id 

## The dataset

The data is from a corpus called HC Corpora (www.corpora.heliohost.org). It is composed of a large number of tweets, blogs and news publications. We used this corpus to identify appropriate tokens such as words, punctuation, and numbers. This dataset is used in the Shiny R application.  

- When comparing the highest frequency results using 4-grams, we did not find that 4-grams were helpful in finding the next word in a n-gram. Tri-grams were therefore used in our model.

- A major tradeoff is the amount of data analyzed (corpus size) vs analysis time.

- Adding more lines from the text in the target corpus did not always contribute to a better model accuracy. The model was therefore built based on qualitative n-gram criteria versus quantitative.

--- .class #id 

## Applicability to other predictions

This application could be extended for other language processing predictions, including:  

* Determine a word in a speech-to-text application when a word or phrase was missed.  
* Determine whether a text is computer-generated by identifying the presence of high-probability next-word predictions.  

References:  

* HC Corpora (www.corpora.heliohost.org)  
* Johns Hopkins Data Science Capstone, https://www.coursera.org/course/dsscapstone 
* Generalized Linear Models, http://www.statmethods.net/advstats/glm.html  
